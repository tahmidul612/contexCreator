import os
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from google import genai
from google.genai.types import GenerateContentConfig
import yaml
from tavily import TavilyClient

load_dotenv()

gemini_api = os.getenv("GEMINI_API_KEY")
gemini_client = genai.Client()
tavily_api = os.getenv("TAVILY_API_KEY")
tavily_client = TavilyClient(tavily_api)

app = FastAPI()

def load_prompt(prompt_name: str, filepath: str = "backend/system_prompts.yml") -> str:
    """
    Load a prompt from a YAML file given its name.
    """
    with open(filepath, "r") as file:
        prompts = yaml.safe_load(file)
        return prompts.get(prompt_name, "")

class GenerateRequest(BaseModel):
    query: str = None  # Optionally specify in POST payload

def generate_input(prompt:str):
    response = gemini_client.models.generate_content(
        model="gemini-2.5-flash",
        contents=prompt,
        config=GenerateContentConfig(
            system_instruction=["""
            generate a json output in this format from the given prompt, use your understanding to fill the information:
            {
                "channels": [ /* social handles the creator owns */ ],
                "aspirational_links": [ /* URLs of influencers the user admires */ ],
                "dream_brands": [ "Nike", "HubSpot", ... ],
                "niche_tags": [ "AI marketing", "Notion templates", ... ]
            }
            """]
        )
    )
    return response.text

def generate_search_query(query: str):
    """
    Endpoint to generate content using Gemini.
    """
    system_instruction = load_prompt("gemini_search")
    input_content = query if query else system_instruction

    try:
        response = gemini_client.models.generate_content(
            model="gemini-2.5-flash",
            contents=generate_input(input_content),
            config=GenerateContentConfig(
                system_instruction=[system_instruction]
            )
        )
        return {"result": response.text}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


def parse_gemini_output(output: str) -> dict:
    """
    Parse the JSON output generated by Gemini and return as a Python dict.
    """
    import json

    try:
        # Remove code block markers or whitespace if present
        cleaned = output.strip()
        # Remove markdown code block if included
        if cleaned.startswith("```json"):
            cleaned = cleaned.strip("`")
            cleaned = cleaned.replace("json", "", 1).strip()
        elif cleaned.startswith("```"):
            cleaned = cleaned.strip("`").strip()
        # Parse JSON
        return json.loads(cleaned)
    except Exception as e:
        raise ValueError(f"Error parsing Gemini JSON output: {e}")

def tavily_search_from_gemini(parsed_data: dict, num_results: int = 5) -> list:
    """
    Use TavilyClient to search using parsed Gemini output and return search results.
    """

    # Formulate the search query. Example: search by 'niche_tags' or 'dream_brands'
    # You may adapt this logic as needed.
    query_parts = []
    if "niche_tags" in parsed_data:
        query_parts += parsed_data["niche_tags"]
    if "dream_brands" in parsed_data:
        query_parts += parsed_data["dream_brands"]
    if "channels" in parsed_data:
        query_parts += parsed_data["channels"]
    if "aspirational_links" in parsed_data:
        query_parts += [url for url in parsed_data["aspirational_links"] if isinstance(url, str)]
    search_query = ", ".join(query_parts)

    # Run search
    results = tavily_client.search(query=search_query, search_depth="advanced", max_results=5)
    return results

def tavily_sitemap(urls: list) -> list:
    """
    Generate sitemaps using the Tavily sitemap API for the provided URLs.
    Returns the collected list of all URLs found in sitemaps.
    """
    all_urls = []
    for url in urls:
        try:
            sitemap_result = tavily_client.sitemap(url=url)
            # The API is expected to return a dict with 'urls' key or a similar attribute
            if 'urls' in sitemap_result:
                all_urls.extend(sitemap_result['urls'])
            else:
                all_urls.extend(sitemap_result)
        except Exception as e:
            # Optionally log or handle errors per URL
            continue
    return all_urls

def gemini_filter_urls(search_query: str, sitemap_urls: list) -> list:
    """
    Use Gemini to filter relevant URLs from the sitemap URLs list using the search query.
    Returns a list of URLs deemed relevant by Gemini.
    """
    filter_prompt = (
        "Given the following list of URLs from a sitemap, select the top relevant links "
        "that best match the searcher prompt below. Reply as a JSON array with only the selected URLs.\n\n"
        f"Searcher prompt: {search_query}\n\n"
        "Sitemap URLs:\n"
        + "\n".join(sitemap_urls)
    )
    response = gemini_client.models.generate_content(
        model="gemini-2.5-flash",
        contents=filter_prompt
    )
    import json
    # Parse output as list
    try:
        output = response.text.strip()
        if output.startswith("```json"):
            output = output.strip("`").replace("json", "", 1).strip()
        elif output.startswith("```"):
            output = output.strip("`").strip()
        filtered = json.loads(output)
        # ensure output is a list of URLs
        if isinstance(filtered, list):
            return filtered
    except Exception:
        pass
    # On error, fallback to returning top N or all input URLs
    return sitemap_urls[:5]

def tavily_crawl(urls: list) -> list:
    """
    Use Tavily's web crawler to get content of the given URLs. Returns a list of dicts.
    """
    crawled_data = []
    for url in urls:
        try:
            result = tavily_client.crawl(url=url)
            crawled_data.append({"url": url, "content": result.get("content", "")})
        except Exception as e:
            crawled_data.append({"url": url, "content": "", "error": str(e)})
    return crawled_data

# Example chained usage for an endpoint (not a part of POST /generate for now):
def get_filtered_sitemap_content(search_query: str, input_urls: list):
    sitemap_urls = tavily_sitemap(input_urls)
    relevant_urls = gemini_filter_urls(search_query, sitemap_urls)
    crawl_results = tavily_crawl(relevant_urls)
    return crawl_results

# Example usage:
# after getting Gemini output (response.text)
# parsed = parse_gemini_output(response.text)
# results = tavily_search_from_gemini(parsed)

def generate_social_post(user_input: str, crawled_data: list) -> str:
    """
    Generate a social media post using Gemini, with user input and crawled data as context.

    Args:
        user_input (str): The original search query or user prompt.
        crawled_data (list): List of dicts with 'url' and 'content' from Tavily crawler.

    Returns:
        str: Generated social post (format as requested by the client).
    """
    # Combine context for Gemini
    content_snippets = "\n\n".join(
        [f"URL: {item['url']}\nContent: {item['content'][:500]}" for item in crawled_data if item.get('content')]
    )

    post_prompt = (
        "Given the following user request and relevant web contents, generate a concise social media post. "
        "Format (for the client):\n"
        "\"\"\"\n"
        "POST:\n"
        "<write the post here>\n"
        "SOURCE_URLS:\n"
        "- <url1>\n"
        "- <url2>\n"
        "...up to 5\n"
        "\"\"\"\n\n"
        "USER REQUEST:\n"
        f"{user_input}\n\n"
        "WEB CONTENTS:\n"
        f"{content_snippets}\n"
        "Be engaging and relevant. Only output in the format specified above."
    )

    response = gemini_client.models.generate_content(
        model="gemini-2.5-flash",
        contents=post_prompt
    )
    return response.text.strip()

@app.post("/generate")
def generate_results(query: GenerateRequest):
    gemini_query = generate_input(query.query)
    parsed_query = parse_gemini_output(gemini_query)
    results = tavily_search_from_gemini(parsed_query)
    return results